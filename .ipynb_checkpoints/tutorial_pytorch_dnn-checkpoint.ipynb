{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7206, 0.7409, 0.2712],\n",
      "        [0.0191, 0.3960, 0.8229],\n",
      "        [0.7283, 0.5558, 0.3159],\n",
      "        [0.7252, 0.8978, 0.4456],\n",
      "        [0.1866, 0.6864, 0.2755]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 0.3733,  0.7820, -0.0602],\n",
      "        [ 0.8780, -1.8882, -0.7298],\n",
      "        [-2.0069, -0.3524,  0.3304],\n",
      "        [-0.7622,  0.7858, -0.9743],\n",
      "        [ 0.3937,  0.2817, -0.2101]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.double)\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6368,  1.1030,  0.5563],\n",
      "        [ 1.7214, -1.3006, -0.2182],\n",
      "        [-1.7104, -0.3457,  1.0885],\n",
      "        [-0.3513,  0.8712, -0.8437],\n",
      "        [ 0.5518,  0.7447,  0.2595]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6368,  1.1030,  0.5563],\n",
      "        [ 1.7214, -1.3006, -0.2182],\n",
      "        [-1.7104, -0.3457,  1.0885],\n",
      "        [-0.3513,  0.8712, -0.8437],\n",
      "        [ 0.5518,  0.7447,  0.2595]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6368,  1.1030,  0.5563],\n",
      "        [ 1.7214, -1.3006, -0.2182],\n",
      "        [-1.7104, -0.3457,  1.0885],\n",
      "        [-0.3513,  0.8712, -0.8437],\n",
      "        [ 0.5518,  0.7447,  0.2595]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6368,  1.1030,  0.5563],\n",
      "        [ 1.7214, -1.3006, -0.2182],\n",
      "        [-1.7104, -0.3457,  1.0885],\n",
      "        [-0.3513,  0.8712, -0.8437],\n",
      "        [ 0.5518,  0.7447,  0.2595]])\n"
     ]
    }
   ],
   "source": [
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.7820, -1.8882, -0.3524,  0.7858,  0.2817])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7211])\n",
      "1.7210619449615479\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.7211], device='cuda:0')\n",
      "tensor([2.7211], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    y = torch.ones_like(x, device=device)\n",
    "    x = x.to(device)\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x000002DD24B34A30>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x000002DD24B34310>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 685.0682, -666.1723, -389.8651], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "    \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "y = x.detach()\n",
    "print(y.requires_grad)\n",
    "print(x.eq(y).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[ 0.1116, -0.0359, -0.0852],\n",
      "          [-0.2475, -0.0388, -0.0987],\n",
      "          [ 0.2758, -0.1114, -0.1687]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1505, -0.2064,  0.1566],\n",
      "          [-0.1686, -0.0655,  0.0110],\n",
      "          [-0.1172, -0.2491, -0.1407]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3161,  0.2170,  0.2712],\n",
      "          [-0.2377,  0.2528,  0.0891],\n",
      "          [ 0.1808, -0.2288, -0.3232]]],\n",
      "\n",
      "\n",
      "        [[[-0.2169,  0.2049, -0.0974],\n",
      "          [ 0.2718, -0.2902,  0.1257],\n",
      "          [ 0.2078, -0.1957,  0.2576]]],\n",
      "\n",
      "\n",
      "        [[[-0.0468,  0.1455, -0.1722],\n",
      "          [-0.1035, -0.1538, -0.1438],\n",
      "          [-0.2346,  0.1588,  0.1543]]],\n",
      "\n",
      "\n",
      "        [[[-0.0971,  0.0270, -0.0207],\n",
      "          [ 0.2728, -0.0096, -0.2957],\n",
      "          [ 0.2842,  0.1843,  0.2216]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2754, -0.1126, -0.2129, -0.1286, -0.3224,  0.2556],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 1.2022e-02,  7.7126e-02,  1.0627e-01],\n",
      "          [ 4.1208e-02,  3.4782e-02, -4.5114e-02],\n",
      "          [ 1.0105e-01, -5.5975e-03,  1.1681e-01]],\n",
      "\n",
      "         [[-1.2183e-01,  1.1617e-01, -1.2542e-01],\n",
      "          [-6.3174e-02, -6.3264e-02, -4.4629e-02],\n",
      "          [-4.5443e-03, -5.3934e-02,  7.2515e-02]],\n",
      "\n",
      "         [[ 1.2572e-01,  1.0507e-01, -6.9859e-02],\n",
      "          [ 1.3180e-01,  8.2494e-02,  3.3606e-02],\n",
      "          [ 2.3555e-02,  6.2793e-02, -6.0152e-02]],\n",
      "\n",
      "         [[-1.5709e-02, -1.7366e-02, -1.2772e-01],\n",
      "          [ 1.0515e-01, -1.7029e-02,  1.7777e-03],\n",
      "          [-9.5804e-02, -5.6501e-02, -7.8182e-02]],\n",
      "\n",
      "         [[-1.8402e-02,  1.1608e-01,  1.0068e-01],\n",
      "          [-1.2593e-01,  4.9108e-02, -6.3660e-02],\n",
      "          [ 1.0491e-01, -7.1796e-02, -2.0622e-02]],\n",
      "\n",
      "         [[ 5.9160e-02, -8.6039e-02,  2.8284e-02],\n",
      "          [-2.3263e-02, -3.6446e-03,  6.8906e-02],\n",
      "          [ 2.9485e-02, -9.0029e-02,  1.1071e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3569e-01,  1.6559e-02, -1.0468e-01],\n",
      "          [ 6.7099e-02, -4.9790e-02, -7.5020e-02],\n",
      "          [-2.8885e-03, -7.7546e-02,  8.7398e-02]],\n",
      "\n",
      "         [[-5.1408e-02,  1.0370e-01,  3.7594e-02],\n",
      "          [-2.1981e-02,  5.3909e-02,  6.8025e-02],\n",
      "          [ 1.1691e-01,  1.0210e-01, -1.1317e-01]],\n",
      "\n",
      "         [[ 5.5854e-02,  6.4457e-02,  9.3897e-02],\n",
      "          [-1.2966e-01,  1.2507e-01, -1.1119e-01],\n",
      "          [-8.4673e-03,  1.2113e-01, -1.1670e-01]],\n",
      "\n",
      "         [[ 2.8197e-02,  9.0494e-02,  5.9961e-02],\n",
      "          [ 2.6752e-02,  3.6306e-02,  1.8656e-02],\n",
      "          [ 1.0724e-01, -6.2325e-02, -6.8420e-02]],\n",
      "\n",
      "         [[ 1.4127e-02, -8.4937e-02,  5.6547e-02],\n",
      "          [-4.1589e-02, -1.3476e-01,  7.0908e-02],\n",
      "          [-1.3584e-02,  1.1785e-01, -6.5406e-02]],\n",
      "\n",
      "         [[-6.9926e-02, -1.1920e-02,  2.6055e-02],\n",
      "          [-6.8816e-02, -6.3511e-02,  2.7249e-02],\n",
      "          [-8.0487e-03,  9.0938e-02,  2.2708e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7735e-02,  4.6642e-02, -2.9464e-02],\n",
      "          [-6.9457e-02,  7.7664e-02,  7.3626e-02],\n",
      "          [-4.1909e-03,  7.7447e-02, -5.5700e-02]],\n",
      "\n",
      "         [[ 9.4025e-02, -1.2268e-01, -1.2087e-01],\n",
      "          [-7.3938e-02,  1.3087e-01,  9.3173e-02],\n",
      "          [-6.3187e-02, -1.2017e-01,  2.2318e-02]],\n",
      "\n",
      "         [[ 8.5414e-02,  7.5794e-02,  5.3181e-02],\n",
      "          [ 9.3850e-02, -9.7457e-02,  7.1412e-02],\n",
      "          [ 1.3528e-01,  1.1932e-01, -6.4050e-02]],\n",
      "\n",
      "         [[-7.5738e-02,  1.3555e-01, -7.7015e-02],\n",
      "          [-1.0380e-01,  1.5705e-02, -1.1182e-01],\n",
      "          [-9.3893e-02, -6.5193e-02, -1.2859e-01]],\n",
      "\n",
      "         [[ 9.5862e-02, -9.7719e-02, -1.1589e-01],\n",
      "          [ 4.1168e-02,  6.6240e-02, -3.5011e-02],\n",
      "          [ 8.5221e-02,  1.0564e-01, -6.7596e-02]],\n",
      "\n",
      "         [[ 6.6358e-02,  1.1498e-02,  1.0111e-02],\n",
      "          [-1.1560e-01, -2.6224e-02, -1.7730e-02],\n",
      "          [ 4.0800e-02, -4.1904e-02, -1.1833e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.8800e-03, -1.6681e-03,  3.6528e-02],\n",
      "          [-1.3148e-01,  6.7405e-02, -1.1881e-01],\n",
      "          [ 1.2776e-01, -1.0136e-01,  5.2975e-02]],\n",
      "\n",
      "         [[ 3.5792e-02, -4.9299e-02,  4.3493e-02],\n",
      "          [-1.2358e-01,  3.7702e-02,  8.9019e-02],\n",
      "          [ 3.8747e-02,  2.7084e-02, -9.3069e-02]],\n",
      "\n",
      "         [[ 2.6449e-02,  2.9172e-02,  8.2857e-02],\n",
      "          [-2.5168e-02, -1.0813e-01, -7.3114e-02],\n",
      "          [ 8.0893e-02, -5.8222e-02,  1.3401e-01]],\n",
      "\n",
      "         [[ 1.3127e-01, -3.5830e-02, -2.6727e-02],\n",
      "          [-5.8890e-02, -6.2220e-02,  5.7563e-02],\n",
      "          [ 3.6336e-03, -1.0140e-01,  5.4848e-02]],\n",
      "\n",
      "         [[ 1.8823e-02,  8.5439e-02, -1.8320e-02],\n",
      "          [ 1.1567e-01, -1.1925e-02,  9.2526e-02],\n",
      "          [-5.4134e-02, -3.3491e-02, -4.1742e-02]],\n",
      "\n",
      "         [[-7.5534e-02,  4.7817e-02, -3.4208e-02],\n",
      "          [-7.7133e-02,  1.0401e-01,  9.3528e-02],\n",
      "          [-1.0969e-01, -2.4469e-04,  1.0901e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.3325e-02, -4.1353e-02, -1.3167e-02],\n",
      "          [ 6.1798e-02,  6.4234e-02, -1.3254e-02],\n",
      "          [ 8.5031e-03,  5.8918e-02,  5.8330e-02]],\n",
      "\n",
      "         [[-1.3252e-01, -5.2374e-02, -8.0047e-02],\n",
      "          [ 1.2111e-01,  2.9789e-03, -1.2919e-01],\n",
      "          [ 1.2915e-01,  1.2302e-01, -4.1522e-02]],\n",
      "\n",
      "         [[ 8.3975e-02, -6.3934e-02,  7.0237e-02],\n",
      "          [ 1.2685e-01, -1.1799e-01, -5.0847e-02],\n",
      "          [-3.9828e-02, -7.1803e-02, -1.3213e-01]],\n",
      "\n",
      "         [[ 3.9201e-02, -9.4172e-02,  4.0695e-02],\n",
      "          [-1.1806e-01, -1.2724e-01,  3.3450e-03],\n",
      "          [ 7.3142e-02, -5.0773e-02, -1.3431e-01]],\n",
      "\n",
      "         [[-2.8633e-02,  1.2178e-01,  6.8715e-02],\n",
      "          [-9.5783e-02, -3.9025e-02, -1.2794e-01],\n",
      "          [-2.7557e-02,  7.1335e-02,  7.9443e-02]],\n",
      "\n",
      "         [[-4.5388e-02,  6.7365e-02, -6.8778e-02],\n",
      "          [ 9.9412e-02, -2.6108e-04, -8.9623e-02],\n",
      "          [-1.2443e-01,  1.3006e-01, -7.1110e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3433e-01, -8.5028e-02, -1.6023e-02],\n",
      "          [ 7.0402e-02, -4.3484e-02, -1.0437e-01],\n",
      "          [ 3.2036e-04,  9.4988e-02, -9.1725e-02]],\n",
      "\n",
      "         [[-6.0370e-02,  1.0697e-01, -8.0066e-02],\n",
      "          [-3.9860e-02, -6.2040e-02, -1.2896e-01],\n",
      "          [ 4.4662e-02,  8.0523e-02,  9.5323e-02]],\n",
      "\n",
      "         [[ 3.1758e-02,  9.7422e-03, -1.2662e-01],\n",
      "          [ 2.5126e-02,  6.8929e-02,  8.9652e-02],\n",
      "          [-3.7968e-02, -2.8567e-02,  6.5508e-02]],\n",
      "\n",
      "         [[ 1.1179e-01,  1.3286e-01,  5.1047e-02],\n",
      "          [ 1.7244e-02,  1.1787e-01,  1.5782e-02],\n",
      "          [-7.8165e-02, -3.0297e-03,  1.5611e-02]],\n",
      "\n",
      "         [[ 9.9821e-02, -8.0057e-02,  2.9904e-02],\n",
      "          [ 7.7035e-02,  3.8232e-02,  7.9152e-03],\n",
      "          [ 5.6963e-02,  2.1565e-02,  1.1387e-01]],\n",
      "\n",
      "         [[-1.0663e-01, -3.5038e-02,  8.9628e-02],\n",
      "          [-4.3401e-02, -1.2080e-01, -1.0887e-01],\n",
      "          [ 4.9479e-02, -4.0491e-02,  1.0352e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0292e-01, -3.0696e-02,  4.0878e-02],\n",
      "          [ 5.6297e-02,  1.1137e-01, -9.1487e-02],\n",
      "          [-2.0952e-02, -3.0940e-02,  7.5906e-02]],\n",
      "\n",
      "         [[-1.1166e-01, -7.6850e-02,  1.3739e-02],\n",
      "          [-3.9955e-02, -2.0782e-02, -1.0011e-01],\n",
      "          [ 8.9430e-02,  5.9417e-02,  7.8965e-02]],\n",
      "\n",
      "         [[-9.4251e-02,  2.8730e-02,  1.1293e-01],\n",
      "          [-3.1145e-02,  5.5371e-02,  3.6733e-02],\n",
      "          [-1.5325e-02,  1.2918e-01, -4.3849e-02]],\n",
      "\n",
      "         [[-8.0694e-02, -1.0084e-01, -6.0208e-02],\n",
      "          [-8.4329e-02, -1.0979e-01, -5.5526e-02],\n",
      "          [ 3.4255e-02,  4.5236e-03, -1.1421e-01]],\n",
      "\n",
      "         [[-3.9987e-02,  6.6875e-02,  4.5780e-02],\n",
      "          [ 1.0239e-01,  1.0937e-01,  2.7681e-02],\n",
      "          [ 9.2707e-02, -1.5895e-02,  1.3505e-01]],\n",
      "\n",
      "         [[ 7.4048e-02,  2.6304e-02,  5.3010e-02],\n",
      "          [ 7.9659e-03,  5.3986e-02, -7.0410e-02],\n",
      "          [ 2.0069e-02,  3.3531e-02,  1.1732e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0787e-01,  1.1062e-01,  1.1607e-01],\n",
      "          [-1.2953e-01,  1.1700e-01, -1.7419e-02],\n",
      "          [ 9.1499e-03,  9.2654e-02, -1.1000e-01]],\n",
      "\n",
      "         [[-6.5148e-02,  5.4439e-02, -7.9382e-02],\n",
      "          [ 1.3883e-02, -4.2581e-02,  8.7634e-02],\n",
      "          [-7.8055e-02,  4.0574e-02,  2.1874e-02]],\n",
      "\n",
      "         [[ 4.2091e-02,  1.0661e-01, -1.0551e-01],\n",
      "          [ 1.3553e-01, -9.2389e-02, -1.0446e-01],\n",
      "          [-9.5172e-02, -1.4799e-02,  3.4180e-02]],\n",
      "\n",
      "         [[ 1.1479e-01, -2.4856e-03, -7.1103e-02],\n",
      "          [ 4.3127e-02, -2.2755e-02, -1.0340e-01],\n",
      "          [-5.5144e-02,  8.0794e-02,  6.0068e-02]],\n",
      "\n",
      "         [[ 4.7827e-02,  7.3069e-02,  1.9072e-02],\n",
      "          [ 4.2094e-03, -1.3148e-01, -2.7223e-02],\n",
      "          [ 7.6878e-02,  2.5998e-04,  9.7658e-02]],\n",
      "\n",
      "         [[ 6.0294e-02, -8.7438e-02, -1.2043e-01],\n",
      "          [ 4.9997e-02,  1.2855e-01, -7.2013e-02],\n",
      "          [-8.8677e-02, -6.5360e-02,  7.4289e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1912e-02,  1.8489e-02,  1.2844e-01],\n",
      "          [ 1.5565e-02, -4.4671e-02,  1.6562e-02],\n",
      "          [-5.8108e-02, -7.4323e-02,  8.8046e-02]],\n",
      "\n",
      "         [[ 9.6579e-02, -7.3558e-02, -7.2069e-02],\n",
      "          [-5.7605e-02,  9.3097e-02, -1.1352e-01],\n",
      "          [-5.6243e-02,  1.1638e-02, -5.5065e-02]],\n",
      "\n",
      "         [[-7.6430e-02,  5.5444e-03, -1.0843e-01],\n",
      "          [-1.1516e-01,  6.6666e-02, -8.4783e-03],\n",
      "          [ 8.8004e-02, -7.0204e-03,  3.3639e-02]],\n",
      "\n",
      "         [[-2.2856e-02,  8.0383e-02,  5.7395e-02],\n",
      "          [ 1.4901e-02, -1.2109e-01,  6.8228e-02],\n",
      "          [-1.2310e-01, -4.3738e-02,  1.1393e-01]],\n",
      "\n",
      "         [[ 8.7402e-02, -1.1398e-01,  4.2392e-03],\n",
      "          [ 4.0049e-02,  5.1205e-02,  2.8503e-02],\n",
      "          [-2.7149e-02, -1.1230e-02,  1.2630e-01]],\n",
      "\n",
      "         [[ 1.0393e-01,  4.1950e-02, -8.3847e-02],\n",
      "          [-3.7975e-02,  3.1273e-02,  9.2968e-02],\n",
      "          [-2.9622e-02, -9.8839e-05, -4.5053e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6329e-02,  7.9351e-02, -8.0928e-03],\n",
      "          [ 6.6928e-02,  7.7632e-02,  5.8518e-02],\n",
      "          [-1.2190e-01,  1.3335e-01,  1.5554e-02]],\n",
      "\n",
      "         [[ 7.8948e-02, -1.1766e-01, -5.8926e-02],\n",
      "          [-1.2830e-01, -8.4206e-02,  1.2079e-01],\n",
      "          [-4.5694e-02,  8.4265e-03, -5.3553e-02]],\n",
      "\n",
      "         [[ 8.7153e-02, -1.1426e-01, -5.8588e-02],\n",
      "          [-5.1090e-02, -1.3815e-02, -1.0967e-01],\n",
      "          [-2.5830e-02,  1.0552e-01, -6.5098e-03]],\n",
      "\n",
      "         [[ 6.4657e-03, -1.1449e-01,  1.2541e-01],\n",
      "          [-2.3304e-02,  1.1375e-01, -4.4567e-02],\n",
      "          [-4.2600e-03, -1.0011e-01,  1.2655e-01]],\n",
      "\n",
      "         [[ 1.1273e-01,  1.2785e-01, -2.4582e-02],\n",
      "          [ 5.9055e-02,  9.1865e-02,  1.5342e-03],\n",
      "          [-1.2486e-01,  1.0785e-02, -1.4914e-02]],\n",
      "\n",
      "         [[ 7.0587e-02,  2.9939e-02,  2.3131e-02],\n",
      "          [ 3.1766e-02,  4.4948e-02, -1.1814e-01],\n",
      "          [ 8.6465e-02,  1.8209e-02, -7.4973e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.1711e-02, -4.2235e-02, -1.1879e-02],\n",
      "          [ 3.8064e-02,  1.3561e-01, -3.2050e-02],\n",
      "          [ 4.7873e-02,  8.1909e-02,  2.9009e-02]],\n",
      "\n",
      "         [[ 8.6615e-02, -5.9790e-02, -1.1346e-01],\n",
      "          [-1.0420e-01, -1.1860e-01,  1.1378e-01],\n",
      "          [ 5.7494e-02, -1.3164e-01, -4.0123e-02]],\n",
      "\n",
      "         [[-1.2750e-01,  1.0947e-01, -1.5975e-02],\n",
      "          [ 6.8825e-02, -4.1169e-02,  1.0631e-01],\n",
      "          [ 1.3361e-01, -7.3780e-02,  1.1924e-01]],\n",
      "\n",
      "         [[ 9.6033e-02, -1.3589e-01,  1.0090e-01],\n",
      "          [ 5.5203e-02,  7.1862e-02,  1.1394e-01],\n",
      "          [ 2.7799e-02,  2.7373e-02, -1.6495e-03]],\n",
      "\n",
      "         [[-1.1319e-01,  7.7647e-02, -3.2371e-02],\n",
      "          [ 8.6906e-02,  3.5119e-02, -6.7775e-02],\n",
      "          [-8.2428e-03, -1.2359e-01, -6.4918e-02]],\n",
      "\n",
      "         [[ 1.1279e-01, -1.3520e-01, -9.8982e-02],\n",
      "          [-4.3516e-02,  4.7621e-02,  2.4612e-02],\n",
      "          [ 3.5519e-02, -4.6092e-04, -7.7852e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8425e-02, -4.8991e-02,  4.0758e-02],\n",
      "          [-7.3999e-03,  1.0094e-01, -8.2772e-02],\n",
      "          [-4.5252e-02, -2.2557e-02, -1.7074e-02]],\n",
      "\n",
      "         [[ 3.2020e-02,  1.1739e-01,  1.3373e-01],\n",
      "          [-9.8612e-03,  1.2118e-01,  1.1365e-01],\n",
      "          [-1.0172e-01,  9.1247e-02,  1.0622e-01]],\n",
      "\n",
      "         [[ 1.1350e-01,  2.7226e-02,  8.6933e-02],\n",
      "          [-9.8089e-03, -1.0686e-01, -7.1033e-02],\n",
      "          [ 8.0051e-02, -5.6371e-02,  3.4973e-02]],\n",
      "\n",
      "         [[-8.8094e-02, -1.0396e-01,  4.9833e-02],\n",
      "          [-2.1919e-02, -7.0592e-02,  6.6637e-02],\n",
      "          [ 1.2720e-01,  1.1400e-01, -9.4438e-03]],\n",
      "\n",
      "         [[-1.0888e-02,  3.6188e-02,  2.6882e-02],\n",
      "          [ 4.1538e-02, -8.7155e-02, -1.2847e-01],\n",
      "          [ 1.8451e-02,  9.3322e-02,  8.1862e-02]],\n",
      "\n",
      "         [[ 1.2929e-01, -1.1852e-01, -6.4430e-02],\n",
      "          [ 8.0918e-02, -3.7146e-02, -1.3326e-02],\n",
      "          [ 1.0061e-01, -1.1861e-01,  9.8286e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.7651e-02, -6.1474e-02,  5.6799e-02],\n",
      "          [-2.3628e-02, -3.9544e-02,  2.1978e-02],\n",
      "          [ 9.7976e-02,  5.0612e-02,  1.6679e-03]],\n",
      "\n",
      "         [[-2.8304e-02,  1.9332e-02, -8.8638e-02],\n",
      "          [ 8.8938e-02,  6.7475e-02,  1.1239e-01],\n",
      "          [ 2.7156e-02,  2.3085e-02, -5.6798e-02]],\n",
      "\n",
      "         [[ 7.3064e-02,  5.4704e-02, -5.6849e-02],\n",
      "          [ 3.0619e-02,  9.4832e-02,  1.3062e-01],\n",
      "          [ 3.1699e-02,  4.7485e-02, -1.3607e-01]],\n",
      "\n",
      "         [[ 1.1275e-01,  7.6933e-02, -5.9270e-03],\n",
      "          [-7.4345e-02, -1.2460e-01, -3.7416e-02],\n",
      "          [ 5.5396e-02,  1.0002e-01,  8.0290e-02]],\n",
      "\n",
      "         [[-1.2320e-01, -3.6144e-02,  1.1689e-01],\n",
      "          [-3.5445e-02,  4.5959e-02,  1.2884e-01],\n",
      "          [ 6.1853e-02, -7.4682e-02, -1.2082e-01]],\n",
      "\n",
      "         [[-8.1019e-02,  5.1329e-02,  9.2567e-02],\n",
      "          [ 1.2229e-01,  5.2862e-02, -5.8231e-02],\n",
      "          [ 8.6478e-02, -2.5007e-02,  5.0433e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3652e-02,  2.9535e-02, -9.2786e-02],\n",
      "          [ 2.4952e-02,  1.1273e-01,  9.9979e-02],\n",
      "          [ 1.9075e-02, -4.7281e-02,  1.0753e-01]],\n",
      "\n",
      "         [[-7.5447e-02,  1.1917e-01, -1.0111e-01],\n",
      "          [ 1.0393e-02, -7.8196e-02,  1.2370e-01],\n",
      "          [-1.2940e-01,  9.3079e-02,  3.7277e-02]],\n",
      "\n",
      "         [[-8.6750e-02, -5.9556e-02, -1.2676e-01],\n",
      "          [ 5.5489e-02, -3.8625e-02,  1.0804e-01],\n",
      "          [-1.3444e-01,  1.2440e-01, -9.0404e-02]],\n",
      "\n",
      "         [[-7.6495e-02, -3.2766e-03,  1.1336e-01],\n",
      "          [ 1.7014e-02, -2.6545e-02,  4.0673e-03],\n",
      "          [-1.1266e-01, -6.9032e-02,  1.1845e-01]],\n",
      "\n",
      "         [[ 8.8918e-02,  1.2823e-02, -8.7074e-02],\n",
      "          [ 5.0774e-02, -2.8349e-02, -7.1115e-03],\n",
      "          [-7.5141e-02, -8.1980e-02, -2.1894e-02]],\n",
      "\n",
      "         [[-2.0312e-02, -1.2633e-01, -1.2954e-01],\n",
      "          [-8.8549e-02, -4.5734e-02,  7.4166e-02],\n",
      "          [ 4.0296e-02,  3.8346e-02,  3.5189e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.2480e-02,  2.2432e-03, -8.4593e-02],\n",
      "          [ 3.7867e-02,  8.3299e-02,  2.1993e-02],\n",
      "          [ 7.7379e-02,  7.2164e-02,  1.2922e-01]],\n",
      "\n",
      "         [[ 7.5198e-02,  1.0443e-01,  6.3443e-02],\n",
      "          [-7.2471e-02,  9.9009e-04, -2.1741e-02],\n",
      "          [-1.1152e-01, -1.1916e-01,  1.3501e-01]],\n",
      "\n",
      "         [[ 3.7951e-02,  9.8844e-02, -2.5249e-02],\n",
      "          [ 1.2481e-01,  8.8264e-02,  3.1626e-02],\n",
      "          [ 5.4409e-02, -2.8416e-02,  7.4942e-02]],\n",
      "\n",
      "         [[ 1.3226e-01, -8.9677e-02,  8.5735e-02],\n",
      "          [-5.3740e-02, -1.7424e-02,  1.0430e-01],\n",
      "          [-1.0039e-01, -5.0245e-02, -2.3644e-03]],\n",
      "\n",
      "         [[-3.0152e-02, -1.1656e-01,  2.7537e-02],\n",
      "          [-7.5784e-02,  5.4018e-02, -2.2182e-02],\n",
      "          [-5.7331e-02, -8.2367e-02, -1.5496e-02]],\n",
      "\n",
      "         [[ 4.2151e-02, -6.5781e-03, -6.9198e-02],\n",
      "          [-1.0075e-01, -8.3403e-03, -7.6056e-02],\n",
      "          [-2.9009e-02, -1.1126e-01,  8.4126e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2544e-01, -3.2232e-02, -1.0221e-01],\n",
      "          [ 1.5535e-02,  1.1515e-01, -6.5676e-02],\n",
      "          [ 8.2475e-02, -4.7740e-02,  1.2494e-01]],\n",
      "\n",
      "         [[ 4.6497e-02, -3.4446e-02,  8.7004e-02],\n",
      "          [ 1.3267e-01, -7.2690e-02,  9.6483e-02],\n",
      "          [-1.0134e-01, -6.4436e-02,  8.3566e-02]],\n",
      "\n",
      "         [[-8.3524e-02, -1.3945e-04, -7.1458e-02],\n",
      "          [-8.4415e-02, -3.7426e-02, -1.2866e-02],\n",
      "          [ 1.1484e-01, -8.1457e-02, -1.1593e-02]],\n",
      "\n",
      "         [[-8.7317e-02,  7.7363e-03,  1.3330e-01],\n",
      "          [-8.6522e-02,  7.1526e-02,  2.7806e-02],\n",
      "          [-8.0539e-03, -4.5873e-02,  7.6528e-02]],\n",
      "\n",
      "         [[-1.0390e-02, -1.2621e-01, -1.0057e-01],\n",
      "          [ 5.3524e-02, -2.5175e-02,  5.5413e-02],\n",
      "          [-9.1234e-02,  5.1454e-02,  1.1415e-01]],\n",
      "\n",
      "         [[-6.4146e-02,  5.7102e-02,  9.2157e-02],\n",
      "          [ 9.7100e-02, -3.5849e-02,  2.7241e-03],\n",
      "          [ 4.8024e-02,  1.1490e-01,  1.2499e-01]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1114,  0.1109,  0.0594,  0.0960, -0.1166, -0.1023, -0.0450,  0.0485,\n",
      "        -0.0252, -0.1203,  0.0381,  0.1151, -0.0543,  0.0157, -0.0045,  0.0013],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0146,  0.0051, -0.0218,  ..., -0.0395,  0.0405, -0.0081],\n",
      "        [-0.0289,  0.0365,  0.0083,  ...,  0.0192,  0.0114, -0.0136],\n",
      "        [ 0.0105, -0.0240, -0.0382,  ..., -0.0414,  0.0116, -0.0086],\n",
      "        ...,\n",
      "        [ 0.0011, -0.0391, -0.0138,  ..., -0.0194,  0.0298,  0.0209],\n",
      "        [-0.0144, -0.0343,  0.0384,  ..., -0.0026, -0.0024,  0.0215],\n",
      "        [ 0.0262,  0.0067,  0.0397,  ..., -0.0278,  0.0206,  0.0104]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-2.3369e-02, -1.1808e-02, -3.0688e-02, -3.3852e-02,  3.8836e-02,\n",
      "         1.5132e-03, -3.6206e-02,  5.1984e-03,  4.0163e-02,  4.5720e-04,\n",
      "        -2.8395e-02,  4.1482e-02,  2.8241e-02,  2.2737e-03, -4.0860e-02,\n",
      "        -2.4570e-03,  5.3606e-03,  3.0461e-02,  3.9070e-02, -1.8714e-02,\n",
      "        -8.8231e-03, -4.0208e-02, -4.0798e-03, -3.8796e-02,  2.4152e-02,\n",
      "         1.8053e-02, -1.9591e-03, -2.7295e-02,  2.1484e-02, -1.5325e-02,\n",
      "         3.4835e-02, -3.1560e-02, -1.3581e-02, -3.4490e-02, -7.9365e-03,\n",
      "         1.7372e-02,  1.3226e-02, -2.7467e-02, -2.7279e-02, -1.0868e-02,\n",
      "        -1.4526e-02,  1.4718e-02,  1.1908e-02, -2.6602e-03,  2.1165e-02,\n",
      "         3.4260e-02,  2.0122e-02,  3.1480e-04, -1.2406e-03, -5.5803e-03,\n",
      "        -8.2821e-05,  4.0861e-02,  7.4694e-03, -4.1994e-03, -3.3429e-02,\n",
      "        -2.2167e-03,  4.2184e-04,  5.9743e-03, -1.2779e-03,  3.2828e-02,\n",
      "         4.0975e-02, -3.6403e-02,  8.9335e-04, -2.5121e-02,  2.0940e-02,\n",
      "        -4.1610e-02,  2.0451e-02,  4.0172e-02,  1.6555e-02, -3.2387e-02,\n",
      "        -2.0676e-02, -1.2854e-02,  1.4568e-02, -1.1629e-02, -2.3775e-02,\n",
      "         2.4448e-03,  1.4286e-02,  3.6956e-02, -1.9537e-03,  3.4383e-02,\n",
      "        -7.4798e-03, -2.8175e-02,  1.2167e-02,  3.1973e-02, -3.0405e-02,\n",
      "        -7.4494e-03,  3.5903e-02, -3.9599e-02,  4.0755e-02, -2.3221e-02,\n",
      "         3.2105e-02, -3.1093e-02, -2.5432e-02,  1.3661e-02, -1.0402e-02,\n",
      "        -1.1559e-02, -2.1002e-02,  3.2482e-02,  1.3837e-02,  7.6960e-03,\n",
      "         2.4064e-03,  7.0797e-03,  5.6684e-03, -3.2747e-02,  1.8611e-02,\n",
      "         3.0889e-02, -7.3969e-03, -1.0604e-02,  3.3770e-02,  1.3400e-03,\n",
      "        -1.5291e-02,  3.8160e-02,  1.4512e-02,  1.3043e-02,  1.0130e-02,\n",
      "        -2.8837e-02,  2.7996e-02, -4.0153e-02,  1.8424e-02,  2.9647e-02],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0303, -0.0254, -0.0679,  ..., -0.0126,  0.0779, -0.0455],\n",
      "        [-0.0426, -0.0239,  0.0549,  ...,  0.0332, -0.0182, -0.0475],\n",
      "        [ 0.0808,  0.0314, -0.0421,  ..., -0.0339,  0.0526,  0.0661],\n",
      "        ...,\n",
      "        [ 0.0564,  0.0403, -0.0418,  ..., -0.0352,  0.0095,  0.0154],\n",
      "        [ 0.0050,  0.0530, -0.0443,  ...,  0.0723,  0.0223, -0.0206],\n",
      "        [ 0.0495, -0.0843, -0.0334,  ...,  0.0215,  0.0390, -0.0089]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 5.3473e-02,  6.4474e-02,  6.3983e-02,  4.1421e-02, -8.3936e-02,\n",
      "        -3.4964e-02,  5.8610e-02,  7.4531e-02,  1.6622e-02,  8.1204e-02,\n",
      "         6.3824e-02, -1.4818e-02,  6.3595e-02, -4.9509e-02,  6.6477e-02,\n",
      "        -1.2940e-03,  7.1397e-02, -3.6782e-02,  2.2969e-02,  3.4619e-02,\n",
      "        -6.0885e-02,  3.0533e-02,  8.7798e-02, -1.9492e-02, -4.7880e-02,\n",
      "        -5.9673e-03,  5.6502e-02,  5.2392e-02, -6.4825e-02, -2.2387e-02,\n",
      "         7.9669e-05,  8.4501e-02,  1.4338e-02, -7.8147e-02,  7.1057e-02,\n",
      "         2.1734e-02,  5.1615e-02,  7.3509e-02, -7.6150e-02, -3.7061e-02,\n",
      "         7.4998e-02, -4.9577e-02,  3.8572e-02, -4.9251e-02, -4.8837e-02,\n",
      "         3.4622e-02,  3.3360e-02,  8.7680e-02, -7.8755e-02, -3.2328e-02,\n",
      "        -6.5161e-02,  6.2960e-02,  2.9624e-02, -4.9514e-02, -3.9452e-03,\n",
      "         7.0060e-02, -1.6336e-02,  3.0929e-02, -7.9134e-02,  7.5046e-02,\n",
      "        -3.8305e-02, -8.6906e-02, -8.2729e-03,  3.4980e-02,  1.2436e-02,\n",
      "         7.9214e-02,  5.9386e-02,  1.9552e-03,  8.9076e-02,  8.0215e-02,\n",
      "         7.3704e-02,  7.2408e-02,  8.0601e-02,  3.4061e-02, -4.9742e-02,\n",
      "         3.4382e-02, -8.9528e-02, -1.8968e-02, -3.2006e-02, -5.2976e-02,\n",
      "        -5.6800e-02,  1.9355e-02, -3.8047e-02, -6.6441e-02],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0151,  0.0188,  0.0968, -0.0491,  0.0695, -0.0790,  0.0747, -0.0735,\n",
      "          0.0569, -0.0039, -0.0326, -0.0960,  0.1052, -0.0646,  0.0205, -0.0447,\n",
      "          0.0796, -0.1015,  0.0937,  0.0576,  0.0940,  0.0333,  0.0830, -0.0206,\n",
      "          0.1008, -0.0314, -0.0576, -0.1017,  0.0913, -0.0517,  0.0343,  0.0852,\n",
      "          0.0905,  0.0583,  0.0460,  0.0230, -0.0395, -0.0137,  0.0641,  0.0283,\n",
      "         -0.0367,  0.1040,  0.0274, -0.0172, -0.0089, -0.0043, -0.0174,  0.0892,\n",
      "          0.0669, -0.0773,  0.0525, -0.0463, -0.0947, -0.0474, -0.0154,  0.0718,\n",
      "         -0.0841,  0.1042, -0.0362, -0.0920,  0.1058, -0.0678,  0.0998, -0.0337,\n",
      "         -0.0920, -0.0060,  0.0719, -0.0859,  0.0340, -0.0179, -0.0538, -0.0895,\n",
      "         -0.0024, -0.0925,  0.0565, -0.1084,  0.0218,  0.0195, -0.0214,  0.0110,\n",
      "         -0.0433, -0.1090,  0.0548,  0.0332],\n",
      "        [ 0.0943, -0.0743, -0.0496, -0.0618, -0.0953, -0.0397,  0.0122, -0.0419,\n",
      "         -0.0844, -0.0356, -0.1055, -0.0386,  0.0513,  0.0894, -0.1080, -0.1012,\n",
      "          0.0331,  0.0049,  0.1083, -0.0535, -0.0997, -0.1011, -0.0220,  0.1042,\n",
      "          0.0353, -0.0318,  0.0196,  0.0045,  0.0018,  0.0633,  0.0541,  0.1050,\n",
      "         -0.0367,  0.0948, -0.0031,  0.1064,  0.0202,  0.0843, -0.0128,  0.0563,\n",
      "         -0.0589, -0.0628,  0.0732,  0.0708,  0.0363,  0.0044,  0.0489,  0.0936,\n",
      "         -0.1001, -0.0028,  0.0759,  0.0881, -0.0934,  0.0585,  0.0216, -0.0168,\n",
      "          0.0857, -0.1061, -0.0062,  0.1009, -0.0840,  0.0707,  0.1028, -0.0440,\n",
      "          0.0097,  0.0003, -0.0410,  0.0082,  0.0191, -0.0776,  0.0655, -0.0759,\n",
      "          0.0558, -0.0366,  0.0372,  0.0441,  0.0867,  0.1061,  0.0870,  0.0573,\n",
      "          0.0466,  0.0824, -0.0877,  0.1041],\n",
      "        [-0.1030, -0.1086,  0.0641,  0.0753,  0.0685, -0.0106, -0.0331,  0.0877,\n",
      "          0.0938, -0.0134,  0.0333,  0.0881,  0.0889,  0.0892,  0.0778,  0.0942,\n",
      "         -0.0706, -0.0506, -0.0297,  0.0898, -0.0192,  0.0075, -0.0048,  0.0555,\n",
      "          0.0053,  0.0202, -0.0586, -0.0438,  0.0494, -0.0212,  0.0463,  0.0300,\n",
      "         -0.0810, -0.0656, -0.0477, -0.0530,  0.0456, -0.0078, -0.0550, -0.0279,\n",
      "          0.0730,  0.0883, -0.0262,  0.0196,  0.0069, -0.0468,  0.0968,  0.0949,\n",
      "         -0.0184,  0.0981, -0.0192, -0.0062, -0.0181, -0.0632,  0.0871,  0.0521,\n",
      "         -0.0222,  0.0686, -0.0739,  0.0599,  0.0032,  0.0775,  0.0533, -0.0296,\n",
      "          0.0197, -0.0095, -0.0948, -0.0920, -0.0936,  0.0160,  0.0146, -0.0912,\n",
      "          0.0720,  0.0731,  0.0543,  0.0918,  0.0531,  0.0548, -0.1075, -0.1064,\n",
      "          0.0920,  0.0463,  0.0204, -0.0749],\n",
      "        [ 0.0752, -0.0776,  0.0398, -0.0444, -0.0386,  0.0935,  0.0862, -0.1022,\n",
      "          0.1060, -0.1006,  0.0315,  0.0578, -0.0612, -0.0868,  0.0926, -0.0554,\n",
      "          0.1081, -0.0837,  0.0912, -0.1018,  0.0164,  0.1083, -0.0737, -0.0458,\n",
      "          0.0213,  0.0008, -0.0567, -0.0929, -0.0127, -0.0637,  0.0030,  0.1061,\n",
      "         -0.0297,  0.0259, -0.0201,  0.0798,  0.0677, -0.0221, -0.0135,  0.0859,\n",
      "          0.0992, -0.0286, -0.0519,  0.0430, -0.0483,  0.0310, -0.0894, -0.0101,\n",
      "         -0.0682, -0.0627, -0.0723, -0.0488,  0.0355, -0.0295, -0.0907, -0.0600,\n",
      "         -0.0640, -0.0627, -0.0684, -0.0458,  0.0736,  0.0020,  0.0061,  0.0848,\n",
      "          0.0042,  0.0342,  0.0687,  0.0228, -0.0339, -0.0958, -0.0499,  0.0437,\n",
      "          0.0706, -0.0745, -0.0440, -0.0945, -0.0724,  0.0815,  0.0110, -0.0556,\n",
      "          0.0384, -0.0587, -0.0640,  0.0710],\n",
      "        [-0.0520,  0.1073,  0.0321,  0.0779, -0.0593,  0.0635, -0.0815,  0.0831,\n",
      "         -0.0604, -0.0597, -0.0392,  0.0887,  0.1022, -0.0392, -0.0366, -0.0798,\n",
      "         -0.0079, -0.0804, -0.0675, -0.0570,  0.0866,  0.0793,  0.1090, -0.0018,\n",
      "          0.0260, -0.0286,  0.0050,  0.0263,  0.0013, -0.0483, -0.0088, -0.0690,\n",
      "         -0.0350,  0.1014,  0.0124, -0.1043,  0.0052, -0.0706, -0.1010, -0.0956,\n",
      "          0.0127, -0.0831,  0.0806,  0.1006,  0.0885, -0.0282,  0.0759, -0.0617,\n",
      "         -0.0068, -0.1085, -0.0446, -0.0550, -0.0334, -0.0818,  0.0742, -0.0431,\n",
      "          0.0777,  0.0477,  0.0034, -0.0863,  0.0899, -0.0990, -0.0694,  0.1091,\n",
      "          0.0886, -0.0916, -0.0101, -0.0157, -0.0220, -0.1054, -0.0689, -0.0776,\n",
      "         -0.0182,  0.1040,  0.0159, -0.1074, -0.0292, -0.0338,  0.0388, -0.0637,\n",
      "          0.0755,  0.0266, -0.0452, -0.0319],\n",
      "        [-0.0397, -0.0574,  0.0833,  0.0353, -0.0527,  0.0674,  0.0288,  0.0280,\n",
      "         -0.0303,  0.0191, -0.0420,  0.0722,  0.0696, -0.0459,  0.0496, -0.0390,\n",
      "          0.0379,  0.0452,  0.0080, -0.0701, -0.0474,  0.0261,  0.0971, -0.0655,\n",
      "         -0.1025,  0.0675, -0.0236,  0.0215,  0.1075,  0.0278,  0.0301, -0.0454,\n",
      "         -0.0141, -0.0378, -0.0802,  0.0512,  0.0458,  0.0066, -0.0012,  0.0543,\n",
      "         -0.0620, -0.0994,  0.0335, -0.0197,  0.0786, -0.0420,  0.0644, -0.0176,\n",
      "         -0.0472, -0.0961,  0.0011,  0.1013, -0.0494,  0.1070, -0.0232,  0.0017,\n",
      "         -0.0992,  0.0701, -0.0969,  0.0237, -0.0089, -0.0776,  0.0870, -0.0129,\n",
      "          0.0458, -0.0188,  0.0536,  0.0398,  0.1047,  0.0833,  0.0529, -0.0204,\n",
      "         -0.0876, -0.0109, -0.0644, -0.0320, -0.0945,  0.0773, -0.1046, -0.0129,\n",
      "          0.0099, -0.0195, -0.0232, -0.0291],\n",
      "        [-0.1061,  0.0940, -0.0618,  0.0027,  0.0781,  0.0551,  0.0659, -0.0387,\n",
      "          0.0928,  0.0862, -0.0289, -0.0483,  0.0880, -0.0274, -0.0308,  0.0561,\n",
      "         -0.1084,  0.0793,  0.0353,  0.0202,  0.0874,  0.0016,  0.0038,  0.0207,\n",
      "          0.0343, -0.0402,  0.0724, -0.0688,  0.0288,  0.0237, -0.0843,  0.0023,\n",
      "          0.0781, -0.0707,  0.1003, -0.0622,  0.0468,  0.0900, -0.0656,  0.0953,\n",
      "          0.0957,  0.0315, -0.0766,  0.0746,  0.0197, -0.0860,  0.0870, -0.0529,\n",
      "          0.0975,  0.0935,  0.0673, -0.1046,  0.1015, -0.0872, -0.0967,  0.1035,\n",
      "         -0.1014, -0.0876,  0.0346, -0.0785, -0.0684, -0.0859,  0.0479,  0.0667,\n",
      "         -0.0432, -0.0442,  0.0362,  0.0457, -0.0624, -0.1077, -0.0627, -0.0943,\n",
      "         -0.0753, -0.0844, -0.0791, -0.0720, -0.0332, -0.0302, -0.0813, -0.0734,\n",
      "         -0.0693,  0.0045,  0.0669, -0.0717],\n",
      "        [ 0.0280, -0.0210, -0.0829, -0.0262,  0.0417, -0.0744,  0.0279, -0.0635,\n",
      "         -0.0039,  0.0402, -0.0748,  0.0618, -0.0350,  0.0302, -0.0383,  0.0071,\n",
      "         -0.0181,  0.0253, -0.0772, -0.0453, -0.0797, -0.0622,  0.0289,  0.0352,\n",
      "         -0.0541,  0.0701, -0.1068, -0.0525, -0.1015,  0.0255, -0.0743, -0.0122,\n",
      "          0.0385,  0.0714, -0.0602,  0.0379, -0.0777,  0.0195,  0.0742, -0.1067,\n",
      "          0.0725, -0.0356,  0.0423,  0.0443,  0.0092, -0.0515, -0.1037,  0.0557,\n",
      "          0.0548, -0.0660,  0.0693,  0.0329, -0.0346, -0.0354,  0.0083, -0.0301,\n",
      "         -0.0576, -0.0225, -0.0455, -0.0558,  0.0953,  0.1029,  0.1043, -0.0782,\n",
      "          0.0818, -0.1048, -0.0199, -0.0309, -0.0639,  0.0221, -0.0285,  0.0244,\n",
      "         -0.0411, -0.0312,  0.1075, -0.0409, -0.1005,  0.0866,  0.0748,  0.0526,\n",
      "         -0.0445,  0.0587, -0.0907,  0.0383],\n",
      "        [ 0.0432,  0.0354, -0.1006, -0.0165, -0.0133,  0.0851, -0.0671,  0.1074,\n",
      "         -0.0358,  0.0426,  0.0471,  0.0781, -0.0588, -0.0970, -0.0329,  0.0860,\n",
      "          0.0256, -0.0137,  0.0356, -0.0695, -0.0124, -0.0235, -0.0857,  0.0593,\n",
      "         -0.0625,  0.0427,  0.0770, -0.1089, -0.0572, -0.0226,  0.0054,  0.0475,\n",
      "         -0.0510,  0.0521, -0.0180,  0.0488, -0.0459,  0.0926,  0.0007, -0.0916,\n",
      "         -0.0900, -0.0337, -0.0843,  0.0413, -0.0867, -0.0190, -0.0112,  0.0004,\n",
      "          0.0138,  0.0142, -0.0402,  0.0303,  0.0304,  0.0945,  0.0531,  0.0075,\n",
      "         -0.0116,  0.0813, -0.0123,  0.0895, -0.0573,  0.0038, -0.0891,  0.0786,\n",
      "          0.0089, -0.0866, -0.0418,  0.0644,  0.0145,  0.0307,  0.0545,  0.0551,\n",
      "         -0.0787, -0.0594, -0.1056,  0.0718,  0.0085, -0.0566,  0.0502,  0.0832,\n",
      "         -0.0702, -0.0548, -0.0434,  0.0498],\n",
      "        [ 0.0715,  0.0883, -0.0608,  0.0221,  0.0824, -0.0155,  0.0969,  0.0458,\n",
      "          0.1014, -0.0842, -0.0467, -0.0301,  0.0957,  0.1062,  0.0251, -0.0093,\n",
      "         -0.0783, -0.0254, -0.0917, -0.0834, -0.0811, -0.0906,  0.0492,  0.0048,\n",
      "          0.0365, -0.0510, -0.0475,  0.0225, -0.0868,  0.0251,  0.0772, -0.0270,\n",
      "         -0.0009, -0.0061,  0.0755,  0.0908,  0.0437,  0.0869, -0.1076,  0.0745,\n",
      "          0.1068, -0.0646,  0.0798, -0.1069, -0.0204,  0.0816, -0.0599, -0.0777,\n",
      "          0.0956, -0.0243,  0.0744, -0.0713,  0.1018,  0.0791,  0.0796, -0.0717,\n",
      "         -0.0003, -0.1019, -0.0393, -0.0545,  0.0367, -0.0761,  0.0923, -0.0767,\n",
      "         -0.0841,  0.0851,  0.0143, -0.0978, -0.0090, -0.0308,  0.0377,  0.0383,\n",
      "         -0.0157, -0.0855, -0.0052, -0.0178,  0.1040,  0.0930,  0.0428, -0.0793,\n",
      "          0.0282,  0.0695,  0.0333,  0.0571]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0576,  0.0907, -0.0957,  0.0923,  0.0710, -0.0381,  0.0873,  0.0409,\n",
      "        -0.0709, -0.0390], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0341,  0.1481,  0.0020,  0.0969,  0.0011, -0.0579,  0.0847, -0.0122,\n",
      "         -0.1087, -0.0172]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2927, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)\n",
    "target = target.view(1, -1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x000002DD24B4C520>\n",
      "<AddmmBackward object at 0x000002DD24B4C640>\n",
      "<AccumulateGrad object at 0x000002DD24B4C520>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)\n",
    "print(loss.grad_fn.next_functions[0][0])\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0154,  0.0300, -0.0125,  0.0251, -0.0102,  0.0234])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim as optim\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# optimizer.zero_grad()\n",
    "# output = net(input)\n",
    "# lozz = criterion(output, target)\n",
    "# loss.backward()\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
